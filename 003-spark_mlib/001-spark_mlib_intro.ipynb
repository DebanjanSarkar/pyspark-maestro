{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a35a2792-f9e0-4178-a9b7-091bd95d6d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a360c37c-98ca-4b8f-8744-6512d2ebaca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "586cddcb-5d63-48e8-a273-1570a4a34644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://CBLLAP3157:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark MLib Intro</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x17e9a007190>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Spark MLib Intro\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecbbb088-5c09-4927-a345-34f35b1281de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     name|age|experience|salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df = spark.read.csv( \"./data/employee_salary.csv\", header=True, inferSchema=True )\n",
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "373496ed-7d31-4842-96ca-a815f868df27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- experience: integer (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "985f126e-c626-4289-830c-6a2eecc0b073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'string'), ('age', 'int'), ('experience', 'int'), ('salary', 'int')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3292f67f-16cc-456b-a5a1-e64af0a252ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'age', 'experience', 'salary']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4690a59-8127-4988-ba04-072ada15f5da",
   "metadata": {},
   "source": [
    "- For spark MLib, to perform and apply different machine learning algorithms on any dataset, we have a specific kind of data processing, in which we need to collate all the data columns that forms the independent feature, in following way: \\\n",
    "`[independent_feature_1, independent_feature_2, ...., independent_feature_n]` \\\n",
    "This group of independent features is called a **VectorAssembler**(a class in python). This group then becomes a new, different, independent feature.\n",
    "- In our case, the independent features are `age` and `experience`, and they are grouped as below: \\\n",
    "  `[\"age\", \"experience\"]`\n",
    "- Every record is grouped like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "771923b9-77c4-4266-aff5-bd05bbfdd00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fbe9a79-46dc-412f-974e-9f21f43ad41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_feature_group = VectorAssembler( inputCols=[\"age\", \"experience\"], outputCol=\"Independent Features\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "185f6e78-8dbe-43ba-8950-bcb43e36f7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.feature.VectorAssembler'>\n"
     ]
    }
   ],
   "source": [
    "print(type(independent_feature_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd3750d2-d0b5-4f3c-bf91-c09dc688275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = independent_feature_group.transform( emp_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9749890b-5d31-4895-b4d9-a5e493254a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+--------------------+\n",
      "|     name|age|experience|salary|Independent Features|\n",
      "+---------+---+----------+------+--------------------+\n",
      "|    Krish| 31|        10| 30000|         [31.0,10.0]|\n",
      "|Sudhanshu| 30|         8| 25000|          [30.0,8.0]|\n",
      "|    Sunny| 29|         4| 20000|          [29.0,4.0]|\n",
      "|     Paul| 24|         3| 20000|          [24.0,3.0]|\n",
      "|   Harsha| 21|         1| 15000|          [21.0,1.0]|\n",
      "|  Shubham| 23|         2| 18000|          [23.0,2.0]|\n",
      "+---------+---+----------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed791852-dc5f-4aae-8d08-a761d3ac4799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|Independent Features|salary|\n",
      "+--------------------+------+\n",
      "|         [31.0,10.0]| 30000|\n",
      "|          [30.0,8.0]| 25000|\n",
      "|          [29.0,4.0]| 20000|\n",
      "|          [24.0,3.0]| 20000|\n",
      "|          [21.0,1.0]| 15000|\n",
      "|          [23.0,2.0]| 18000|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df = output_df.select( [\"Independent Features\", \"salary\"] )\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ffc091a-bb17-4499-9b2f-a56e83b4f3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print( type(final_df) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af72a3c5-2883-4a53-8aaf-c5e2ff60dc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Training data and testing data split\n",
    "train_data_df, test_data_df = final_df.randomSplit([0.75, 0.25])\n",
    "print( type(train_data_df) )\n",
    "print( type(test_data_df) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18d4b9b9-e01d-4838-961f-db409c833576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|Independent Features|salary|\n",
      "+--------------------+------+\n",
      "|          [21.0,1.0]| 15000|\n",
      "|          [24.0,3.0]| 20000|\n",
      "|          [29.0,4.0]| 20000|\n",
      "|          [30.0,8.0]| 25000|\n",
      "+--------------------+------+\n",
      "\n",
      "+--------------------+------+\n",
      "|Independent Features|salary|\n",
      "+--------------------+------+\n",
      "|          [23.0,2.0]| 18000|\n",
      "|         [31.0,10.0]| 30000|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data_df.show()\n",
    "test_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65c09041-5a65-422e-841f-89656b29bd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dffe216e-4fbc-4971-9108-32703feec079",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_regressor = LinearRegression( featuresCol=\"Independent Features\", labelCol=\"salary\" )\n",
    "salary_regressor = salary_regressor.fit( train_data_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a58c7db-c981-436a-95c5-cad32a3c3b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([47.619, 1285.7143])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coefficients\n",
    "salary_regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4196cced-4ab3-482d-b6e8-0fc201375760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13619.047619047662"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intercept\n",
    "salary_regressor.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e43b3cf8-980f-444f-8e23-c552af9b8670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "pred_results = salary_regressor.evaluate( test_data_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d6fa87d9-2569-4d59-aedb-2baba8fb45e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.regression.LinearRegressionSummary'>\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pred_results))\n",
    "print(type( pred_results.predictions ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab8e2b78-a14e-4999-acd9-b5244735aab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----------------+\n",
      "|Independent Features|salary|       prediction|\n",
      "+--------------------+------+-----------------+\n",
      "|          [23.0,2.0]| 18000|17285.71428571428|\n",
      "|         [31.0,10.0]| 30000|27952.38095238097|\n",
      "+--------------------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7730eff3-10f9-4331-945e-958f29bf5ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1380.9523809523762"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results.meanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95192f6d-50c4-4346-afb6-31e9eac95a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1533.4516369623352"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bd50ff-16cc-471b-b896-67c43e076da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
