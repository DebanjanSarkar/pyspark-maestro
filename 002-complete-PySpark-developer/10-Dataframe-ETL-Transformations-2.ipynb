{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62097949-2208-46ca-81a0-f1b03f2cf222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46bd37c3-8716-48bc-ad39-a9f4d3871a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"10-Dataframe-ETL-Transformations-2\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ae15b80-2532-4c1b-80ea-56ce25f25b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7471edc-76bc-4708-987f-ed6dbb887648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DEBANJAN:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>10-Dataframe-ETL-Transformations-2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x169416a03d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62430c78-4a86-42d0-aa73-16e5496fa3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.shuffle.partitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b4c7c6-ddb0-4fd4-9ca4-c8f084bef736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81624bb3-a8e5-40e9-aab7-ad153d135e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", sc.defaultParallelism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa7420ab-8286-4f62-a83f-b4d1034680b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'true'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.codegen.wholeStage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad6716f0-8c2a-45fa-8cd4-963b52a514e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa90eaab-2fac-4403-99f5-c00e47745681",
   "metadata": {},
   "source": [
    "# 1. Window Functions:-\n",
    "--------------------------\n",
    "- For applying window functions on dataframes, we have the classes ***Window*** and ***WindowSpec***, in the ***pyspark.sql.window*** module.\n",
    "- Both the above classes has 4 main APIs/methods: ***partitionBy(), orderBy(), rangeBetween(), rowsBetween()***\n",
    "- On applying any of the above 4 APIs(with suitable parameters) on the ***Window*** object, a ***WindowSpec*** object is returned.\n",
    "- However, the windows functions like ***row_number(), rank(), dense_rank()*** are in the ***pyspark.sql.functions*** module. These functions take ***WindowSpec*** object as parameter of the ***over()*** method, that these window functions has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9529d64b-1959-402a-b5b0-4bd4ce539491",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module pyspark.sql.window in pyspark.sql:\n",
      "\n",
      "NAME\n",
      "    pyspark.sql.window\n",
      "\n",
      "DESCRIPTION\n",
      "    # Licensed to the Apache Software Foundation (ASF) under one or more\n",
      "    # contributor license agreements.  See the NOTICE file distributed with\n",
      "    # this work for additional information regarding copyright ownership.\n",
      "    # The ASF licenses this file to You under the Apache License, Version 2.0\n",
      "    # (the \"License\"); you may not use this file except in compliance with\n",
      "    # the License.  You may obtain a copy of the License at\n",
      "    #\n",
      "    #    http://www.apache.org/licenses/LICENSE-2.0\n",
      "    #\n",
      "    # Unless required by applicable law or agreed to in writing, software\n",
      "    # distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "    # See the License for the specific language governing permissions and\n",
      "    # limitations under the License.\n",
      "    #\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        Window\n",
      "        WindowSpec\n",
      "    \n",
      "    class Window(builtins.object)\n",
      "     |  Utility functions for defining window in DataFrames.\n",
      "     |  \n",
      "     |  .. versionadded:: 1.4\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  When ordering is not defined, an unbounded window frame (rowFrame,\n",
      "     |  unboundedPreceding, unboundedFollowing) is used by default. When ordering is defined,\n",
      "     |  a growing window frame (rangeFrame, unboundedPreceding, currentRow) is used by default.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> # ORDER BY date ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
      "     |  >>> window = Window.orderBy(\"date\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
      "     |  \n",
      "     |  >>> # PARTITION BY country ORDER BY date RANGE BETWEEN 3 PRECEDING AND 3 FOLLOWING\n",
      "     |  >>> window = Window.orderBy(\"date\").partitionBy(\"country\").rangeBetween(-3, 3)\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  orderBy(*cols: Union[ForwardRef('ColumnOrName'), List[ForwardRef('ColumnOrName_')]]) -> 'WindowSpec'\n",
      "     |      Creates a :class:`WindowSpec` with the ordering defined.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.4\n",
      "     |  \n",
      "     |  partitionBy(*cols: Union[ForwardRef('ColumnOrName'), List[ForwardRef('ColumnOrName_')]]) -> 'WindowSpec'\n",
      "     |      Creates a :class:`WindowSpec` with the partitioning defined.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.4\n",
      "     |  \n",
      "     |  rangeBetween(start: int, end: int) -> 'WindowSpec'\n",
      "     |      Creates a :class:`WindowSpec` with the frame boundaries defined,\n",
      "     |      from `start` (inclusive) to `end` (inclusive).\n",
      "     |      \n",
      "     |      Both `start` and `end` are relative from the current row. For example,\n",
      "     |      \"0\" means \"current row\", while \"-1\" means one off before the current row,\n",
      "     |      and \"5\" means the five off after the current row.\n",
      "     |      \n",
      "     |      We recommend users use ``Window.unboundedPreceding``, ``Window.unboundedFollowing``,\n",
      "     |      and ``Window.currentRow`` to specify special boundary values, rather than using integral\n",
      "     |      values directly.\n",
      "     |      \n",
      "     |      A range-based boundary is based on the actual value of the ORDER BY\n",
      "     |      expression(s). An offset is used to alter the value of the ORDER BY expression, for\n",
      "     |      instance if the current ORDER BY expression has a value of 10 and the lower bound offset\n",
      "     |      is -3, the resulting lower bound for the current row will be 10 - 3 = 7. This however puts a\n",
      "     |      number of constraints on the ORDER BY expressions: there can be only one expression and this\n",
      "     |      expression must have a numerical data type. An exception can be made when the offset is\n",
      "     |      unbounded, because no value modification is needed, in this case multiple and non-numeric\n",
      "     |      ORDER BY expression are allowed.\n",
      "     |      \n",
      "     |      .. versionadded:: 2.1.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start : int\n",
      "     |          boundary start, inclusive.\n",
      "     |          The frame is unbounded if this is ``Window.unboundedPreceding``, or\n",
      "     |          any value less than or equal to max(-sys.maxsize, -9223372036854775808).\n",
      "     |      end : int\n",
      "     |          boundary end, inclusive.\n",
      "     |          The frame is unbounded if this is ``Window.unboundedFollowing``, or\n",
      "     |          any value greater than or equal to min(sys.maxsize, 9223372036854775807).\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> from pyspark.sql import Window\n",
      "     |      >>> from pyspark.sql import functions as func\n",
      "     |      >>> from pyspark.sql import SQLContext\n",
      "     |      >>> sc = SparkContext.getOrCreate()\n",
      "     |      >>> sqlContext = SQLContext(sc)\n",
      "     |      >>> tup = [(1, \"a\"), (1, \"a\"), (2, \"a\"), (1, \"b\"), (2, \"b\"), (3, \"b\")]\n",
      "     |      >>> df = sqlContext.createDataFrame(tup, [\"id\", \"category\"])\n",
      "     |      >>> window = Window.partitionBy(\"category\").orderBy(\"id\").rangeBetween(Window.currentRow, 1)\n",
      "     |      >>> df.withColumn(\"sum\", func.sum(\"id\").over(window)).sort(\"id\", \"category\").show()\n",
      "     |      +---+--------+---+\n",
      "     |      | id|category|sum|\n",
      "     |      +---+--------+---+\n",
      "     |      |  1|       a|  4|\n",
      "     |      |  1|       a|  4|\n",
      "     |      |  1|       b|  3|\n",
      "     |      |  2|       a|  2|\n",
      "     |      |  2|       b|  5|\n",
      "     |      |  3|       b|  3|\n",
      "     |      +---+--------+---+\n",
      "     |  \n",
      "     |  rowsBetween(start: int, end: int) -> 'WindowSpec'\n",
      "     |      Creates a :class:`WindowSpec` with the frame boundaries defined,\n",
      "     |      from `start` (inclusive) to `end` (inclusive).\n",
      "     |      \n",
      "     |      Both `start` and `end` are relative positions from the current row.\n",
      "     |      For example, \"0\" means \"current row\", while \"-1\" means the row before\n",
      "     |      the current row, and \"5\" means the fifth row after the current row.\n",
      "     |      \n",
      "     |      We recommend users use ``Window.unboundedPreceding``, ``Window.unboundedFollowing``,\n",
      "     |      and ``Window.currentRow`` to specify special boundary values, rather than using integral\n",
      "     |      values directly.\n",
      "     |      \n",
      "     |      A row based boundary is based on the position of the row within the partition.\n",
      "     |      An offset indicates the number of rows above or below the current row, the frame for the\n",
      "     |      current row starts or ends. For instance, given a row based sliding frame with a lower bound\n",
      "     |      offset of -1 and a upper bound offset of +2. The frame for row with index 5 would range from\n",
      "     |      index 4 to index 7.\n",
      "     |      \n",
      "     |      .. versionadded:: 2.1.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start : int\n",
      "     |          boundary start, inclusive.\n",
      "     |          The frame is unbounded if this is ``Window.unboundedPreceding``, or\n",
      "     |          any value less than or equal to -9223372036854775808.\n",
      "     |      end : int\n",
      "     |          boundary end, inclusive.\n",
      "     |          The frame is unbounded if this is ``Window.unboundedFollowing``, or\n",
      "     |          any value greater than or equal to 9223372036854775807.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> from pyspark.sql import Window\n",
      "     |      >>> from pyspark.sql import functions as func\n",
      "     |      >>> from pyspark.sql import SQLContext\n",
      "     |      >>> sc = SparkContext.getOrCreate()\n",
      "     |      >>> sqlContext = SQLContext(sc)\n",
      "     |      >>> tup = [(1, \"a\"), (1, \"a\"), (2, \"a\"), (1, \"b\"), (2, \"b\"), (3, \"b\")]\n",
      "     |      >>> df = sqlContext.createDataFrame(tup, [\"id\", \"category\"])\n",
      "     |      >>> window = Window.partitionBy(\"category\").orderBy(\"id\").rowsBetween(Window.currentRow, 1)\n",
      "     |      >>> df.withColumn(\"sum\", func.sum(\"id\").over(window)).sort(\"id\", \"category\", \"sum\").show()\n",
      "     |      +---+--------+---+\n",
      "     |      | id|category|sum|\n",
      "     |      +---+--------+---+\n",
      "     |      |  1|       a|  2|\n",
      "     |      |  1|       a|  3|\n",
      "     |      |  1|       b|  3|\n",
      "     |      |  2|       a|  2|\n",
      "     |      |  2|       b|  5|\n",
      "     |      |  3|       b|  3|\n",
      "     |      +---+--------+---+\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {'currentRow': <class 'int'>, 'unboundedFollowing': ...\n",
      "     |  \n",
      "     |  currentRow = 0\n",
      "     |  \n",
      "     |  unboundedFollowing = 9223372036854775807\n",
      "     |  \n",
      "     |  unboundedPreceding = -9223372036854775808\n",
      "    \n",
      "    class WindowSpec(builtins.object)\n",
      "     |  WindowSpec(jspec: py4j.java_gateway.JavaObject) -> None\n",
      "     |  \n",
      "     |  A window specification that defines the partitioning, ordering,\n",
      "     |  and frame boundaries.\n",
      "     |  \n",
      "     |  Use the static methods in :class:`Window` to create a :class:`WindowSpec`.\n",
      "     |  \n",
      "     |  .. versionadded:: 1.4.0\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, jspec: py4j.java_gateway.JavaObject) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  orderBy(self, *cols: Union[ForwardRef('ColumnOrName'), List[ForwardRef('ColumnOrName_')]]) -> 'WindowSpec'\n",
      "     |      Defines the ordering columns in a :class:`WindowSpec`.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.4.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cols : str, :class:`Column` or list\n",
      "     |          names of columns or expressions\n",
      "     |  \n",
      "     |  partitionBy(self, *cols: Union[ForwardRef('ColumnOrName'), List[ForwardRef('ColumnOrName_')]]) -> 'WindowSpec'\n",
      "     |      Defines the partitioning columns in a :class:`WindowSpec`.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.4.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cols : str, :class:`Column` or list\n",
      "     |          names of columns or expressions\n",
      "     |  \n",
      "     |  rangeBetween(self, start: int, end: int) -> 'WindowSpec'\n",
      "     |      Defines the frame boundaries, from `start` (inclusive) to `end` (inclusive).\n",
      "     |      \n",
      "     |      Both `start` and `end` are relative from the current row. For example,\n",
      "     |      \"0\" means \"current row\", while \"-1\" means one off before the current row,\n",
      "     |      and \"5\" means the five off after the current row.\n",
      "     |      \n",
      "     |      We recommend users use ``Window.unboundedPreceding``, ``Window.unboundedFollowing``,\n",
      "     |      and ``Window.currentRow`` to specify special boundary values, rather than using integral\n",
      "     |      values directly.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.4.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start : int\n",
      "     |          boundary start, inclusive.\n",
      "     |          The frame is unbounded if this is ``Window.unboundedPreceding``, or\n",
      "     |          any value less than or equal to max(-sys.maxsize, -9223372036854775808).\n",
      "     |      end : int\n",
      "     |          boundary end, inclusive.\n",
      "     |          The frame is unbounded if this is ``Window.unboundedFollowing``, or\n",
      "     |          any value greater than or equal to min(sys.maxsize, 9223372036854775807).\n",
      "     |  \n",
      "     |  rowsBetween(self, start: int, end: int) -> 'WindowSpec'\n",
      "     |      Defines the frame boundaries, from `start` (inclusive) to `end` (inclusive).\n",
      "     |      \n",
      "     |      Both `start` and `end` are relative positions from the current row.\n",
      "     |      For example, \"0\" means \"current row\", while \"-1\" means the row before\n",
      "     |      the current row, and \"5\" means the fifth row after the current row.\n",
      "     |      \n",
      "     |      We recommend users use ``Window.unboundedPreceding``, ``Window.unboundedFollowing``,\n",
      "     |      and ``Window.currentRow`` to specify special boundary values, rather than using integral\n",
      "     |      values directly.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.4.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start : int\n",
      "     |          boundary start, inclusive.\n",
      "     |          The frame is unbounded if this is ``Window.unboundedPreceding``, or\n",
      "     |          any value less than or equal to max(-sys.maxsize, -9223372036854775808).\n",
      "     |      end : int\n",
      "     |          boundary end, inclusive.\n",
      "     |          The frame is unbounded if this is ``Window.unboundedFollowing``, or\n",
      "     |          any value greater than or equal to min(sys.maxsize, 9223372036854775807).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['Window', 'WindowSpec']\n",
      "\n",
      "FILE\n",
      "    d:\\softwares\\apache_spark\\spark\\python\\pyspark\\sql\\window.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "\n",
    "help( pyspark.sql.window )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dfbd20-e0a0-4805-890e-35a8d1cac9d2",
   "metadata": {},
   "source": [
    "## Ranking Window Functions:-\n",
    "-------------------------------\n",
    "- ***row_number()***\n",
    "- ***rank()***\n",
    "- ***dense_rank()***\n",
    "- ***percent_rank()***\n",
    "- ***ntile(n)***\n",
    "- ***cume_dist()***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84f6cb31-126b-4dd2-b62d-40ff0b27da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_data = [\n",
    "    (\"James\", \"Sales\",\"NY\",9000,34),\n",
    "    (\"Alicia\", \"Sales\",\"NY\",8600,56), \n",
    "    (\"Robert\",\"Sales\",\"CA\",8100,30),\n",
    "    (\"John\", \"Sales\",\"AZ\", 8600,31),\n",
    "    (\"Ross\",\"Sales\",\"AZ\",8100,33),\n",
    "    (\"Kathy\", \"Sales\", \"AZ\", 1000, 39),\n",
    "    (\"Lisa\",\"Finance\", \"CA\", 9000,24),\n",
    "    (\"Deja\", \"Finance\",\"CA\",9900,40), \n",
    "    (\"Sugie\",\"Finance\",\"NY\",8300,36),\n",
    "    (\"Ram\", \"Finance\",\"NY\",7900,53),\n",
    "    (\"Satya\", \"Finance\", \"AZ\", 8200, 53),\n",
    "    (\"Kyle\", \"Marketing\",\"CA\",8000,25),\n",
    "    (\"Reid\", \"Marketing\",\"NY\",9100,50)\n",
    "]\n",
    "\n",
    "emp_schema = [\"empname\",\"dept\",\"state\",\"salary\",\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3ed3b67-b07c-4c51-86bb-b2b00b0a8fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df = spark.createDataFrame( data = emp_data, schema = emp_schema )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b62c4bc9-6fd7-43ac-bb0b-5bd65cf797e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+\n",
      "|empname|     dept|state|salary|age|\n",
      "+-------+---------+-----+------+---+\n",
      "|  James|    Sales|   NY|  9000| 34|\n",
      "| Alicia|    Sales|   NY|  8600| 56|\n",
      "| Robert|    Sales|   CA|  8100| 30|\n",
      "|   John|    Sales|   AZ|  8600| 31|\n",
      "|   Ross|    Sales|   AZ|  8100| 33|\n",
      "|  Kathy|    Sales|   AZ|  1000| 39|\n",
      "|   Lisa|  Finance|   CA|  9000| 24|\n",
      "|   Deja|  Finance|   CA|  9900| 40|\n",
      "|  Sugie|  Finance|   NY|  8300| 36|\n",
      "|    Ram|  Finance|   NY|  7900| 53|\n",
      "|  Satya|  Finance|   AZ|  8200| 53|\n",
      "|   Kyle|Marketing|   CA|  8000| 25|\n",
      "|   Reid|Marketing|   NY|  9100| 50|\n",
      "+-------+---------+-----+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25af357f-34e0-47be-86b1-62e596c7976f",
   "metadata": {},
   "source": [
    "### Apply ranking on the salaries of each department, with the highest salary being ranked at the top:\n",
    "<hr>\n",
    "\n",
    "As we are taking salary department wise, partitioning will be based on ***dept*** column, and as ranking is based on salaries, thus ordering will be done based on ***ssalary*** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47c58d38-9239-49da-a2fe-0fbae536c7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window, WindowSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81ff523e-820a-40fb-a548-0fc74e193c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.window.WindowSpec"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_spec_obj = Window.partitionBy( emp_df.dept ).orderBy( emp_df.salary.desc() )\n",
    "type( salary_spec_obj )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59158b3d-f14a-4bba-b11f-3734a8987dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+---------------------------+\n",
      "|empname|     dept|salary|row_number_dept_wise_salary|\n",
      "+-------+---------+------+---------------------------+\n",
      "|   Deja|  Finance|  9900|                          1|\n",
      "|   Lisa|  Finance|  9000|                          2|\n",
      "|  Sugie|  Finance|  8300|                          3|\n",
      "|  Satya|  Finance|  8200|                          4|\n",
      "|    Ram|  Finance|  7900|                          5|\n",
      "|   Reid|Marketing|  9100|                          1|\n",
      "|   Kyle|Marketing|  8000|                          2|\n",
      "|  James|    Sales|  9000|                          1|\n",
      "| Alicia|    Sales|  8600|                          2|\n",
      "|   John|    Sales|  8600|                          3|\n",
      "| Robert|    Sales|  8100|                          4|\n",
      "|   Ross|    Sales|  8100|                          5|\n",
      "|  Kathy|    Sales|  1000|                          6|\n",
      "+-------+---------+------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.drop(\"state\", \"age\").withColumn( \"row_number_dept_wise_salary\", F.row_number().over( salary_spec_obj ) ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e2282a2-444b-4dc4-a536-55dc88cccaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+-----------+\n",
      "|empname|     dept|salary|rank_salary|\n",
      "+-------+---------+------+-----------+\n",
      "|   Deja|  Finance|  9900|          1|\n",
      "|   Lisa|  Finance|  9000|          2|\n",
      "|  Sugie|  Finance|  8300|          3|\n",
      "|  Satya|  Finance|  8200|          4|\n",
      "|    Ram|  Finance|  7900|          5|\n",
      "|   Reid|Marketing|  9100|          1|\n",
      "|   Kyle|Marketing|  8000|          2|\n",
      "|  James|    Sales|  9000|          1|\n",
      "| Alicia|    Sales|  8600|          2|\n",
      "|   John|    Sales|  8600|          2|\n",
      "| Robert|    Sales|  8100|          4|\n",
      "|   Ross|    Sales|  8100|          4|\n",
      "|  Kathy|    Sales|  1000|          6|\n",
      "+-------+---------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.drop(\"state\",\"age\").withColumn(\"rank_salary\", F.rank().over(salary_spec_obj) ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43d4f68b-3826-4ab0-96ab-3d7c9f48452b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+--------------------------+\n",
      "|empname|     dept|salary|dense_rank_salary_deptwise|\n",
      "+-------+---------+------+--------------------------+\n",
      "|   Deja|  Finance|  9900|                         1|\n",
      "|   Lisa|  Finance|  9000|                         2|\n",
      "|  Sugie|  Finance|  8300|                         3|\n",
      "|  Satya|  Finance|  8200|                         4|\n",
      "|    Ram|  Finance|  7900|                         5|\n",
      "|   Reid|Marketing|  9100|                         1|\n",
      "|   Kyle|Marketing|  8000|                         2|\n",
      "|  James|    Sales|  9000|                         1|\n",
      "| Alicia|    Sales|  8600|                         2|\n",
      "|   John|    Sales|  8600|                         2|\n",
      "| Robert|    Sales|  8100|                         3|\n",
      "|   Ross|    Sales|  8100|                         3|\n",
      "|  Kathy|    Sales|  1000|                         4|\n",
      "+-------+---------+------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.drop(\"state\",\"age\").withColumn(\"dense_rank_salary_deptwise\", F.dense_rank().over(salary_spec_obj) ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ab2286a-f6b7-43cb-bd0c-4838f4da3b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+------------+\n",
      "|empname|     dept|salary|percent_rank|\n",
      "+-------+---------+------+------------+\n",
      "|   Deja|  Finance|  9900|         0.0|\n",
      "|   Lisa|  Finance|  9000|        0.25|\n",
      "|  Sugie|  Finance|  8300|         0.5|\n",
      "|  Satya|  Finance|  8200|        0.75|\n",
      "|    Ram|  Finance|  7900|         1.0|\n",
      "|   Reid|Marketing|  9100|         0.0|\n",
      "|   Kyle|Marketing|  8000|         1.0|\n",
      "|  James|    Sales|  9000|         0.0|\n",
      "| Alicia|    Sales|  8600|         0.2|\n",
      "|   John|    Sales|  8600|         0.2|\n",
      "| Robert|    Sales|  8100|         0.6|\n",
      "|   Ross|    Sales|  8100|         0.6|\n",
      "|  Kathy|    Sales|  1000|         1.0|\n",
      "+-------+---------+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.drop(\"state\",\"age\").withColumn(\"percent_rank\", F.percent_rank().over(salary_spec_obj) ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da98343e-f300-4afa-994f-f0aa135513d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+-----+\n",
      "|empname|     dept|salary|ntile|\n",
      "+-------+---------+------+-----+\n",
      "|   Deja|  Finance|  9900|    1|\n",
      "|   Lisa|  Finance|  9000|    1|\n",
      "|  Sugie|  Finance|  8300|    1|\n",
      "|  Satya|  Finance|  8200|    2|\n",
      "|    Ram|  Finance|  7900|    2|\n",
      "|   Reid|Marketing|  9100|    1|\n",
      "|   Kyle|Marketing|  8000|    2|\n",
      "|  James|    Sales|  9000|    1|\n",
      "| Alicia|    Sales|  8600|    1|\n",
      "|   John|    Sales|  8600|    1|\n",
      "| Robert|    Sales|  8100|    2|\n",
      "|   Ross|    Sales|  8100|    2|\n",
      "|  Kathy|    Sales|  1000|    2|\n",
      "+-------+---------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ntile(n) divides group into 'n' parts\n",
    "\n",
    "emp_df.drop(\"state\",\"age\").withColumn(\"ntile\", F.ntile(2).over(salary_spec_obj)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb479b05-8a1b-4cc5-8486-c4c5035929ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+-------------------+\n",
      "|empname|     dept|salary|          cume_dist|\n",
      "+-------+---------+------+-------------------+\n",
      "|   Deja|  Finance|  9900|                0.2|\n",
      "|   Lisa|  Finance|  9000|                0.4|\n",
      "|  Sugie|  Finance|  8300|                0.6|\n",
      "|  Satya|  Finance|  8200|                0.8|\n",
      "|    Ram|  Finance|  7900|                1.0|\n",
      "|   Reid|Marketing|  9100|                0.5|\n",
      "|   Kyle|Marketing|  8000|                1.0|\n",
      "|  James|    Sales|  9000|0.16666666666666666|\n",
      "| Alicia|    Sales|  8600|                0.5|\n",
      "|   John|    Sales|  8600|                0.5|\n",
      "| Robert|    Sales|  8100| 0.8333333333333334|\n",
      "|   Ross|    Sales|  8100| 0.8333333333333334|\n",
      "|  Kathy|    Sales|  1000|                1.0|\n",
      "+-------+---------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.drop(\"state\",\"age\").withColumn(\"cume_dist\", F.cume_dist().over(salary_spec_obj) ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b1e5af-aa60-4231-9253-d6c231d5518f",
   "metadata": {},
   "source": [
    "## Analytical Window Functions:-\n",
    "----------------------------------\n",
    "- ***lead()***\n",
    "- ***lag()***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66bc9685-de3e-4f39-9bc7-eff33c5672b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+\n",
      "|empname|     dept|state|salary|age|\n",
      "+-------+---------+-----+------+---+\n",
      "|  James|    Sales|   NY|  9000| 34|\n",
      "| Alicia|    Sales|   NY|  8600| 56|\n",
      "| Robert|    Sales|   CA|  8100| 30|\n",
      "|   John|    Sales|   AZ|  8600| 31|\n",
      "|   Ross|    Sales|   AZ|  8100| 33|\n",
      "|  Kathy|    Sales|   AZ|  1000| 39|\n",
      "|   Lisa|  Finance|   CA|  9000| 24|\n",
      "|   Deja|  Finance|   CA|  9900| 40|\n",
      "|  Sugie|  Finance|   NY|  8300| 36|\n",
      "|    Ram|  Finance|   NY|  7900| 53|\n",
      "|  Satya|  Finance|   AZ|  8200| 53|\n",
      "|   Kyle|Marketing|   CA|  8000| 25|\n",
      "|   Reid|Marketing|   NY|  9100| 50|\n",
      "+-------+---------+-----+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c53959d0-4202-4eef-8104-3df53b2eea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window, WindowSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "203eb5c9-ec42-46e8-b9d9-9d531d03ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_sal_spec = Window.partitionBy( \"dept\" ).orderBy( \"salary\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "044bf13b-6ce0-4502-988a-6fc25fe47e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+\n",
      "|empname|     dept|salary|\n",
      "+-------+---------+------+\n",
      "|  James|    Sales|  9000|\n",
      "| Alicia|    Sales|  8600|\n",
      "| Robert|    Sales|  8100|\n",
      "|   John|    Sales|  8600|\n",
      "|   Ross|    Sales|  8100|\n",
      "|  Kathy|    Sales|  1000|\n",
      "|   Lisa|  Finance|  9000|\n",
      "|   Deja|  Finance|  9900|\n",
      "|  Sugie|  Finance|  8300|\n",
      "|    Ram|  Finance|  7900|\n",
      "|  Satya|  Finance|  8200|\n",
      "|   Kyle|Marketing|  8000|\n",
      "|   Reid|Marketing|  9100|\n",
      "+-------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_sal_df = emp_df.drop(\"state\", \"age\")\n",
    "dept_sal_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c60a7dd-9f71-4fde-a009-60f7f60e7a24",
   "metadata": {},
   "source": [
    "### With default offset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "384cc9ae-fcdd-4278-824e-4c19adabf8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+--------------------+-------------------+\n",
      "|empname|     dept|salary|lead_salary_deptwise|lag_salary_deptwise|\n",
      "+-------+---------+------+--------------------+-------------------+\n",
      "|    Ram|  Finance|  7900|                8200|               null|\n",
      "|  Satya|  Finance|  8200|                8300|               7900|\n",
      "|  Sugie|  Finance|  8300|                9000|               8200|\n",
      "|   Lisa|  Finance|  9000|                9900|               8300|\n",
      "|   Deja|  Finance|  9900|                null|               9000|\n",
      "|   Kyle|Marketing|  8000|                9100|               null|\n",
      "|   Reid|Marketing|  9100|                null|               8000|\n",
      "|  Kathy|    Sales|  1000|                8100|               null|\n",
      "| Robert|    Sales|  8100|                8100|               1000|\n",
      "|   Ross|    Sales|  8100|                8600|               8100|\n",
      "| Alicia|    Sales|  8600|                8600|               8100|\n",
      "|   John|    Sales|  8600|                9000|               8600|\n",
      "|  James|    Sales|  9000|                null|               8600|\n",
      "+-------+---------+------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_sal_df.withColumn(\"lead_salary_deptwise\", F.lead(\"salary\").over(dept_sal_spec) ) \\\n",
    "           .withColumn(\"lag_salary_deptwise\", F.lag(\"salary\").over(dept_sal_spec) ) \\\n",
    "           .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f90a50-53c5-4e65-8c1a-fa161e87ae25",
   "metadata": {},
   "source": [
    "### With custom offset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cc2659f-a390-47ba-ad5a-3d563019de28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+--------------------+-------------------+\n",
      "|empname|     dept|salary|lead_salary_deptwise|lag_salary_deptwise|\n",
      "+-------+---------+------+--------------------+-------------------+\n",
      "|    Ram|  Finance|  7900|                8300|               null|\n",
      "|  Satya|  Finance|  8200|                9000|               null|\n",
      "|  Sugie|  Finance|  8300|                9900|               7900|\n",
      "|   Lisa|  Finance|  9000|                null|               8200|\n",
      "|   Deja|  Finance|  9900|                null|               8300|\n",
      "|   Kyle|Marketing|  8000|                null|               null|\n",
      "|   Reid|Marketing|  9100|                null|               null|\n",
      "|  Kathy|    Sales|  1000|                8100|               null|\n",
      "| Robert|    Sales|  8100|                8600|               null|\n",
      "|   Ross|    Sales|  8100|                8600|               1000|\n",
      "| Alicia|    Sales|  8600|                9000|               8100|\n",
      "|   John|    Sales|  8600|                null|               8100|\n",
      "|  James|    Sales|  9000|                null|               8600|\n",
      "+-------+---------+------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_sal_df.withColumn( \"lead_salary_deptwise\", F.lead(\"salary\", 2).over( dept_sal_spec ) ) \\\n",
    "           .withColumn( \"lag_salary_deptwise\", F.lag(\"salary\", 2).over(dept_sal_spec) ) \\\n",
    "           .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c26fcb8-08a8-4809-97d4-1eadbf922a8c",
   "metadata": {},
   "source": [
    "### With default value for *NULL* :\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0751f42f-d022-4e49-b268-ba7c1f2b7671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+--------------------+-------------------+\n",
      "|empname|     dept|salary|lead_salary_deptwise|lag_salary_deptwise|\n",
      "+-------+---------+------+--------------------+-------------------+\n",
      "|    Ram|  Finance|  7900|                8300|                 -1|\n",
      "|  Satya|  Finance|  8200|                9000|                 -1|\n",
      "|  Sugie|  Finance|  8300|                9900|               7900|\n",
      "|   Lisa|  Finance|  9000|                  -1|               8200|\n",
      "|   Deja|  Finance|  9900|                  -1|               8300|\n",
      "|   Kyle|Marketing|  8000|                  -1|                 -1|\n",
      "|   Reid|Marketing|  9100|                  -1|                 -1|\n",
      "|  Kathy|    Sales|  1000|                8100|                 -1|\n",
      "| Robert|    Sales|  8100|                8600|                 -1|\n",
      "|   Ross|    Sales|  8100|                8600|               1000|\n",
      "| Alicia|    Sales|  8600|                9000|               8100|\n",
      "|   John|    Sales|  8600|                  -1|               8100|\n",
      "|  James|    Sales|  9000|                  -1|               8600|\n",
      "+-------+---------+------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_sal_df.withColumn( \"lead_salary_deptwise\", F.lead(\"salary\", 2, -1).over( dept_sal_spec ) ) \\\n",
    "           .withColumn( \"lag_salary_deptwise\", F.lag(\"salary\", 2, -1).over(dept_sal_spec) ) \\\n",
    "           .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc8e0d7-e9e4-445e-86e4-b354ace8d326",
   "metadata": {},
   "source": [
    "### Aggregate Window functions:-\n",
    "----------------------------------\n",
    "The same functions used with groupBy() can be used as window functions also. They must be applied with the ***WindowSpec*** object using the ***over()*** method.\n",
    "\n",
    "The only difference will be that, instead of getting the output of each group as one record, for each record, aggregated value will be shown, which will be same over a group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f261980-4c6d-478f-b0e1-33d4da5eeec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_sal_spec = Window.partitionBy( \"dept\" ).orderBy( \"salary\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9fd76c-e498-4494-82c1-9cc9d87be52a",
   "metadata": {},
   "source": [
    "For ***first()*** and ***last()***, orderBy() is must."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8dd44eb2-844f-402f-89f2-92cac86fffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+----------+---------------------+\n",
      "|empname|     dept|salary|min_salary|max_salary_cumulative|\n",
      "+-------+---------+------+----------+---------------------+\n",
      "|    Ram|  Finance|  7900|      7900|                 7900|\n",
      "|  Satya|  Finance|  8200|      7900|                 8200|\n",
      "|  Sugie|  Finance|  8300|      7900|                 8300|\n",
      "|   Lisa|  Finance|  9000|      7900|                 9000|\n",
      "|   Deja|  Finance|  9900|      7900|                 9900|\n",
      "|   Kyle|Marketing|  8000|      8000|                 8000|\n",
      "|   Reid|Marketing|  9100|      8000|                 9100|\n",
      "|  Kathy|    Sales|  1000|      1000|                 1000|\n",
      "| Robert|    Sales|  8100|      1000|                 8100|\n",
      "|   Ross|    Sales|  8100|      1000|                 8100|\n",
      "| Alicia|    Sales|  8600|      1000|                 8600|\n",
      "|   John|    Sales|  8600|      1000|                 8600|\n",
      "|  James|    Sales|  9000|      1000|                 9000|\n",
      "+-------+---------+------+----------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_sal_df.withColumn(\"min_salary\", F.first(\"salary\").over(dept_sal_spec) ) \\\n",
    "           .withColumn(\"max_salary_cumulative\", F.last(\"salary\").over(dept_sal_spec) ) \\\n",
    "           .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b71d241-4c9a-43dc-b75f-7c63929809f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+------------------------+\n",
      "|empname|     dept|salary|Cumulative_sum_of_salary|\n",
      "+-------+---------+------+------------------------+\n",
      "|    Ram|  Finance|  7900|                    7900|\n",
      "|  Satya|  Finance|  8200|                   16100|\n",
      "|  Sugie|  Finance|  8300|                   24400|\n",
      "|   Lisa|  Finance|  9000|                   33400|\n",
      "|   Deja|  Finance|  9900|                   43300|\n",
      "|   Kyle|Marketing|  8000|                    8000|\n",
      "|   Reid|Marketing|  9100|                   17100|\n",
      "|  Kathy|    Sales|  1000|                    1000|\n",
      "| Robert|    Sales|  8100|                   17200|\n",
      "|   Ross|    Sales|  8100|                   17200|\n",
      "| Alicia|    Sales|  8600|                   34400|\n",
      "|   John|    Sales|  8600|                   34400|\n",
      "|  James|    Sales|  9000|                   43400|\n",
      "+-------+---------+------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_sal_df.withColumn(\"Cumulative_sum_of_salary\", F.sum(\"salary\").over(dept_sal_spec) ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec5c28d-89c9-448c-8ea1-6079d1cbb8f0",
   "metadata": {},
   "source": [
    "## If we apply ***orderBy()*** on the window, and then ***sum()***, it yields cumulative sum for each group like this, as above.\n",
    "\n",
    "To get same total for each record of a group, we **must not use *orderBy()***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f0b2bb2-be67-4141-a093-93ff9d2c0b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_spec = Window.partitionBy(\"dept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff24ff68-b23b-4afc-bb9a-95ab7fc907f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+-----------------+\n",
      "|empname|     dept|salary|dept_total_salary|\n",
      "+-------+---------+------+-----------------+\n",
      "|   Lisa|  Finance|  9000|            43300|\n",
      "|   Deja|  Finance|  9900|            43300|\n",
      "|  Sugie|  Finance|  8300|            43300|\n",
      "|    Ram|  Finance|  7900|            43300|\n",
      "|  Satya|  Finance|  8200|            43300|\n",
      "|   Kyle|Marketing|  8000|            17100|\n",
      "|   Reid|Marketing|  9100|            17100|\n",
      "|  James|    Sales|  9000|            43400|\n",
      "| Alicia|    Sales|  8600|            43400|\n",
      "| Robert|    Sales|  8100|            43400|\n",
      "|   John|    Sales|  8600|            43400|\n",
      "|   Ross|    Sales|  8100|            43400|\n",
      "|  Kathy|    Sales|  1000|            43400|\n",
      "+-------+---------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_sal_df.withColumn( \"dept_total_salary\", F.sum(\"salary\").over(sum_spec) ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6e6f543-dc22-4cd6-9358-2c3e92f1531a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----+----+-----------------+-----+-----+\n",
      "|     dept|salary| min| max|              avg|count|  sum|\n",
      "+---------+------+----+----+-----------------+-----+-----+\n",
      "|  Finance|  9000|7900|9900|           8660.0|    5|43300|\n",
      "|  Finance|  9900|7900|9900|           8660.0|    5|43300|\n",
      "|  Finance|  8300|7900|9900|           8660.0|    5|43300|\n",
      "|  Finance|  7900|7900|9900|           8660.0|    5|43300|\n",
      "|  Finance|  8200|7900|9900|           8660.0|    5|43300|\n",
      "|Marketing|  8000|8000|9100|           8550.0|    2|17100|\n",
      "|Marketing|  9100|8000|9100|           8550.0|    2|17100|\n",
      "|    Sales|  9000|1000|9000|7233.333333333333|    6|43400|\n",
      "|    Sales|  8600|1000|9000|7233.333333333333|    6|43400|\n",
      "|    Sales|  8100|1000|9000|7233.333333333333|    6|43400|\n",
      "|    Sales|  8600|1000|9000|7233.333333333333|    6|43400|\n",
      "|    Sales|  8100|1000|9000|7233.333333333333|    6|43400|\n",
      "|    Sales|  1000|1000|9000|7233.333333333333|    6|43400|\n",
      "+---------+------+----+----+-----------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_sal_df.drop(\"empname\").select(\n",
    "    \"*\",\n",
    "    F.min(\"salary\").over(sum_spec).alias(\"min\"),\n",
    "    F.max(\"salary\").over(sum_spec).alias(\"max\"),\n",
    "    F.avg(\"salary\").over(sum_spec).alias(\"avg\"),\n",
    "    F.count(\"salary\").over(sum_spec).alias(\"count\"),\n",
    "    F.sum(\"salary\").over(sum_spec).alias(\"sum\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cb1405-4daf-458d-b41d-5cc3dde162fe",
   "metadata": {},
   "source": [
    "### Other window functions(specific to pyspark Window class):-\n",
    "---------------------------------------------------------------\n",
    "- ***rangeBetween( start, end )*** \n",
    "- ***rowsBetween()***\n",
    "\n",
    "These methods are applied to the **Window** object while getting the **WindowSpec** object, that is being passed as the parameter to the ***over()*** method. The above two methods can only be applied, when ***orderBy()*** has been applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b4c76f2-41a3-4f44-8dea-76af7ad69584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+\n",
      "|empname|     dept|salary|\n",
      "+-------+---------+------+\n",
      "|  James|    Sales|  9000|\n",
      "| Alicia|    Sales|  8600|\n",
      "| Robert|    Sales|  8100|\n",
      "|   John|    Sales|  8600|\n",
      "|   Ross|    Sales|  8100|\n",
      "|  Kathy|    Sales|  1000|\n",
      "|   Lisa|  Finance|  9000|\n",
      "|   Deja|  Finance|  9900|\n",
      "|  Sugie|  Finance|  8300|\n",
      "|    Ram|  Finance|  7900|\n",
      "|  Satya|  Finance|  8200|\n",
      "|   Kyle|Marketing|  8000|\n",
      "|   Reid|Marketing|  9100|\n",
      "+-------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_sal_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f04c050c-d647-40a4-a308-4e4939e6dc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_range1 = Window.partitionBy(\"dept\").orderBy(\"salary\").rangeBetween( Window.unboundedPreceding, Window.unboundedFollowing )\n",
    "spec_range2 = Window.partitionBy(\"dept\").orderBy(\"salary\").rangeBetween( Window.unboundedPreceding, Window.currentRow )\n",
    "spec_range3 = Window.partitionBy(\"dept\").orderBy(\"salary\").rangeBetween( Window.currentRow, Window.unboundedFollowing )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd3cbef7-635e-4dd4-a3ad-df66ee9da45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+------------+------------+------------+\n",
      "|empname|     dept|salary|total_range1|total_range2|total_range3|\n",
      "+-------+---------+------+------------+------------+------------+\n",
      "|    Ram|  Finance|  7900|       43300|        7900|       43300|\n",
      "|  Satya|  Finance|  8200|       43300|       16100|       35400|\n",
      "|  Sugie|  Finance|  8300|       43300|       24400|       27200|\n",
      "|   Lisa|  Finance|  9000|       43300|       33400|       18900|\n",
      "|   Deja|  Finance|  9900|       43300|       43300|        9900|\n",
      "|   Kyle|Marketing|  8000|       17100|        8000|       17100|\n",
      "|   Reid|Marketing|  9100|       17100|       17100|        9100|\n",
      "|  Kathy|    Sales|  1000|       43400|        1000|       43400|\n",
      "| Robert|    Sales|  8100|       43400|       17200|       42400|\n",
      "|   Ross|    Sales|  8100|       43400|       17200|       42400|\n",
      "| Alicia|    Sales|  8600|       43400|       34400|       26200|\n",
      "|   John|    Sales|  8600|       43400|       34400|       26200|\n",
      "|  James|    Sales|  9000|       43400|       43400|        9000|\n",
      "+-------+---------+------+------------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_sal_df.select(\n",
    "    \"*\",\n",
    "    F.sum(\"salary\").over(spec_range1).alias(\"total_range1\"),\n",
    "    F.sum(\"salary\").over(spec_range2).alias(\"total_range2\"),\n",
    "    F.sum(\"salary\").over(spec_range3).alias(\"total_range3\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ec5dfb9-4867-4e30-8256-a79b4aee4a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_row1 = Window.partitionBy(\"dept\").orderBy(\"salary\").rowsBetween( Window.unboundedPreceding, Window.unboundedFollowing )\n",
    "spec_row2 = Window.partitionBy(\"dept\").orderBy(\"salary\").rowsBetween( Window.unboundedPreceding, Window.currentRow )\n",
    "spec_row3 = Window.partitionBy(\"dept\").orderBy(\"salary\").rowsBetween( Window.currentRow, Window.unboundedFollowing )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6df5264f-1013-4834-9496-2275deb167cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+----------+----------+----------+\n",
      "|empname|     dept|salary|total_row1|total_row2|total_row3|\n",
      "+-------+---------+------+----------+----------+----------+\n",
      "|    Ram|  Finance|  7900|     43300|      7900|     43300|\n",
      "|  Satya|  Finance|  8200|     43300|     16100|     35400|\n",
      "|  Sugie|  Finance|  8300|     43300|     24400|     27200|\n",
      "|   Lisa|  Finance|  9000|     43300|     33400|     18900|\n",
      "|   Deja|  Finance|  9900|     43300|     43300|      9900|\n",
      "|   Kyle|Marketing|  8000|     17100|      8000|     17100|\n",
      "|   Reid|Marketing|  9100|     17100|     17100|      9100|\n",
      "|  Kathy|    Sales|  1000|     43400|      1000|     43400|\n",
      "| Robert|    Sales|  8100|     43400|      9100|     42400|\n",
      "|   Ross|    Sales|  8100|     43400|     17200|     34300|\n",
      "| Alicia|    Sales|  8600|     43400|     25800|     26200|\n",
      "|   John|    Sales|  8600|     43400|     34400|     17600|\n",
      "|  James|    Sales|  9000|     43400|     43400|      9000|\n",
      "+-------+---------+------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_sal_df.select(\n",
    "    \"*\",\n",
    "    F.sum(\"salary\").over(spec_row1).alias(\"total_row1\"),\n",
    "    F.sum(\"salary\").over(spec_row2).alias(\"total_row2\"),\n",
    "    F.sum(\"salary\").over(spec_row3).alias(\"total_row3\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220bf135-8693-4862-85a3-b5adaab5e57a",
   "metadata": {},
   "source": [
    "# 2. Sampling:-\n",
    "----------------\n",
    "- ***sample(withReplacement=None, fraction=None, seed=None)*** - It is a transformation, i.e, it returns a Dataframe, and we need to apply ***show()*** to view the results.\n",
    "\n",
    "For RDD, we also have another function for sampling, called ***takeSample()***, and it was an action, but it does not exist for DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fce5e824-d293-4ac7-8d27-af4bbbc450ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+\n",
      "|empname|     dept|state|salary|age|\n",
      "+-------+---------+-----+------+---+\n",
      "|  James|    Sales|   NY|  9000| 34|\n",
      "| Alicia|    Sales|   NY|  8600| 56|\n",
      "| Robert|    Sales|   CA|  8100| 30|\n",
      "|   John|    Sales|   AZ|  8600| 31|\n",
      "|   Ross|    Sales|   AZ|  8100| 33|\n",
      "|  Kathy|    Sales|   AZ|  1000| 39|\n",
      "|   Lisa|  Finance|   CA|  9000| 24|\n",
      "|   Deja|  Finance|   CA|  9900| 40|\n",
      "|  Sugie|  Finance|   NY|  8300| 36|\n",
      "|    Ram|  Finance|   NY|  7900| 53|\n",
      "|  Satya|  Finance|   AZ|  8200| 53|\n",
      "|   Kyle|Marketing|   CA|  8000| 25|\n",
      "|   Reid|Marketing|   NY|  9100| 50|\n",
      "+-------+---------+-----+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "958c747b-c6df-4b48-8231-e6cae9ce4a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+\n",
      "|empname|     dept|state|salary|age|\n",
      "+-------+---------+-----+------+---+\n",
      "|  James|    Sales|   NY|  9000| 34|\n",
      "|  James|    Sales|   NY|  9000| 34|\n",
      "| Alicia|    Sales|   NY|  8600| 56|\n",
      "| Alicia|    Sales|   NY|  8600| 56|\n",
      "|  Kathy|    Sales|   AZ|  1000| 39|\n",
      "|  Kathy|    Sales|   AZ|  1000| 39|\n",
      "|   Kyle|Marketing|   CA|  8000| 25|\n",
      "+-------+---------+-----+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.sample(True, 0.5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4648c2a9-a9a7-45b2-84a0-683695a2cf62",
   "metadata": {},
   "source": [
    "#### When the 1st parameter is true, duplicate values may occur in the result set, even if the value is present only once in the main dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "73cc32f2-3338-4029-b5c4-e17d0c4d2157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+\n",
      "|empname|     dept|state|salary|age|\n",
      "+-------+---------+-----+------+---+\n",
      "|  James|    Sales|   NY|  9000| 34|\n",
      "| Robert|    Sales|   CA|  8100| 30|\n",
      "|   Ross|    Sales|   AZ|  8100| 33|\n",
      "|  Kathy|    Sales|   AZ|  1000| 39|\n",
      "|   Deja|  Finance|   CA|  9900| 40|\n",
      "|  Sugie|  Finance|   NY|  8300| 36|\n",
      "|  Satya|  Finance|   AZ|  8200| 53|\n",
      "|   Kyle|Marketing|   CA|  8000| 25|\n",
      "|   Reid|Marketing|   NY|  9100| 50|\n",
      "+-------+---------+-----+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.sample(False, 0.5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f49f183d-1642-41bb-993a-ff65d033b323",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'takeSample'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DEBANJ~1\\AppData\\Local\\Temp/ipykernel_1212/159715076.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0memp_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtakeSample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Softwares\\Apache_Spark\\spark\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1986\u001b[0m         \"\"\"\n\u001b[0;32m   1987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1988\u001b[1;33m             raise AttributeError(\n\u001b[0m\u001b[0;32m   1989\u001b[0m                 \u001b[1;34m\"'%s' object has no attribute '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1990\u001b[0m             )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'takeSample'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c033e1-be03-46a6-a7f4-9d4fa4f0deeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
